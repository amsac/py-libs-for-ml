{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+e+8M2ToQpYYmQ+qTX7yy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amsac/py-libs-for-ml/blob/main/tensorflow/tf_and_Keras_deeplizard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xfc8KvMMjM9s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "train_labels = []\n",
        "train_samples = []\n",
        "\n",
        "for i in range(50):\n",
        "  # 5% of younger individual who did experience side effects\n",
        "  random_younger = randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(1)\n",
        "\n",
        "  # 5% older individuals who did not experience side effects\n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(0)\n",
        "\n",
        "for i in range(1000):\n",
        "  # 95% of younger individuals who did not experience side effects\n",
        "  random_younger = randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(0)\n",
        "\n",
        "  # 95% of older individuals who did experience side effects\n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting it to numpy array\n",
        "\n",
        "train_lables = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "#shuffling the data\n",
        "\n",
        "train_lables, train_samples = shuffle(train_lables,train_samples)\n",
        "\n",
        "\n",
        "# for i in train_samples:\n",
        "#   print(i)\n",
        "train_lables.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6bKgPgGmhmS",
        "outputId": "cc5ab9db-df35-48fb-aa4b-672b15b02d54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2100,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the above, if you check train_samples.shape , it will be (2100,)\n",
        "\n",
        "\n",
        "what does it mean? -- it is a 1D array with 2100 rows\n",
        "\n",
        "it would be like [1,2,3,.......2100] but no seperate columns. just a 1-d array\n",
        "\n",
        "\n",
        "but after reshaping , it will get converted to a 2D array with one column and 2100 rows.\n",
        "\n",
        "so the shape will change to (2100,1) that means -> 2100 rows and one column\n",
        "```\n",
        "it would be like [ [1],\n",
        "                   [2],\n",
        "                   ...\n",
        "                   [2100] ]\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_1Es7jZ8uhiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels, label_counts = np.unique(train_lables, return_counts=True)\n",
        "unique_labels,label_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ5R0XrN_kMn",
        "outputId": "3dee4364-faa6-4f7f-9861-12e2ba8511e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([1050, 1050]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MinMaxScaler and Feature Scaling**\n",
        "\n",
        "The code you provided uses MinMaxScaler from scikit-learn, which is a tool for feature scaling. Feature scaling is a crucial step in many machine learning algorithms because it helps to ensure that all features contribute equally to the model's learning process. MinMaxScaler specifically works by scaling the features to a given range, which is (0, 1) by default.\n",
        "\n",
        "**feature_range=(0, 1)**\n",
        "\n",
        "This parameter specifies the desired range for the scaled features.\n",
        "In your code, feature_range=(0, 1) means that the scaler will transform the data such that all values fall between 0 and 1, inclusive.\n",
        "This is a common choice because it preserves the relationships between data points while ensuring that no feature dominates due to a larger scale.\n",
        "It's also beneficial for algorithms that are sensitive to the scale of input features.\n",
        "\n",
        "(0, 1): Preferred for algorithms like neural networks that often work best with input values between 0 and 1. It's also a good general-purpose choice.\n",
        "\n",
        "**reshape(-1, 1)**\n",
        "\n",
        "This part of the code is necessary because MinMaxScaler expects input data in a 2D format (samples, features).\n",
        "Your train_samples array is likely a 1D array, so reshape(-1, 1) is used to transform it into a 2D array with one column.\n",
        "-1 is a special value that automatically calculates the number of rows based on the size of the original array."
      ],
      "metadata": {
        "id": "QzcPvD_5pCCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying scalars\n",
        "\n",
        "scalar = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scalar.fit_transform(train_samples.reshape(-1,1))\n",
        "\n",
        "scaled_train_samples, train_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lfRrXUAnHYI",
        "outputId": "2bbc7476-0f8d-4c16-e8eb-62eddbe79991"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        ],\n",
              "        [0.65517241],\n",
              "        [0.16091954],\n",
              "        ...,\n",
              "        [0.55172414],\n",
              "        [0.64367816],\n",
              "        [0.31034483]]),\n",
              " array([13, 70, 27, ..., 61, 69, 40]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_train_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23XyCVD1xxzI",
        "outputId": "862385ee-f7be-4214-9c1d-9d8d5368e37b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Input\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "SjnCfyPup5-I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**couple of things here**\n",
        "\n",
        "1. sequential model is used\n",
        "2. input of sequential model will be taken care by default , by keras\n",
        "3. we will start by defining the first hidden layer.\n",
        "4. for the first hidden layer, we should specify the shape of input\n",
        "5. select the activation function in each layer\n",
        "6. select the number of output nodes in such a way that, it will correctly specify the classification"
      ],
      "metadata": {
        "id": "z-eSeum5v6HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape = (1,), activation = 'relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2,activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "It9Z0JKzxhIv",
        "outputId": "36cb5560-018b-404d-c12d-b0ad3db3bcaf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m32\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,698\u001b[0m (6.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,698</span> (6.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,698\u001b[0m (6.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,698</span> (6.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LxUD6mN--Lxh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=scaled_train_samples,\n",
        "          y=train_lables,\n",
        "          batch_size=15,\n",
        "          epochs=30,\n",
        "          shuffle=True,\n",
        "          verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tto47fTw-QVi",
        "outputId": "d3f1d35e-1be3-432f-b06d-bc62b161eab9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "140/140 - 2s - 11ms/step - accuracy: 0.5505 - loss: 0.6253\n",
            "Epoch 2/30\n",
            "140/140 - 0s - 1ms/step - accuracy: 0.6362 - loss: 0.6001\n",
            "Epoch 3/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.6895 - loss: 0.5717\n",
            "Epoch 4/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.7467 - loss: 0.5339\n",
            "Epoch 5/30\n",
            "140/140 - 0s - 1ms/step - accuracy: 0.8252 - loss: 0.4796\n",
            "Epoch 6/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.8552 - loss: 0.4339\n",
            "Epoch 7/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.8800 - loss: 0.3939\n",
            "Epoch 8/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.8876 - loss: 0.3612\n",
            "Epoch 9/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9100 - loss: 0.3348\n",
            "Epoch 10/30\n",
            "140/140 - 0s - 1ms/step - accuracy: 0.9200 - loss: 0.3153\n",
            "Epoch 11/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9219 - loss: 0.3002\n",
            "Epoch 12/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9319 - loss: 0.2898\n",
            "Epoch 13/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9319 - loss: 0.2817\n",
            "Epoch 14/30\n",
            "140/140 - 0s - 1ms/step - accuracy: 0.9400 - loss: 0.2751\n",
            "Epoch 15/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9329 - loss: 0.2706\n",
            "Epoch 16/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9433 - loss: 0.2681\n",
            "Epoch 17/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9395 - loss: 0.2649\n",
            "Epoch 18/30\n",
            "140/140 - 0s - 1ms/step - accuracy: 0.9424 - loss: 0.2623\n",
            "Epoch 19/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9424 - loss: 0.2606\n",
            "Epoch 20/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9486 - loss: 0.2597\n",
            "Epoch 21/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9410 - loss: 0.2579\n",
            "Epoch 22/30\n",
            "140/140 - 0s - 1ms/step - accuracy: 0.9471 - loss: 0.2562\n",
            "Epoch 23/30\n",
            "140/140 - 0s - 3ms/step - accuracy: 0.9424 - loss: 0.2558\n",
            "Epoch 24/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9443 - loss: 0.2544\n",
            "Epoch 25/30\n",
            "140/140 - 1s - 4ms/step - accuracy: 0.9467 - loss: 0.2537\n",
            "Epoch 26/30\n",
            "140/140 - 1s - 5ms/step - accuracy: 0.9414 - loss: 0.2530\n",
            "Epoch 27/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9410 - loss: 0.2516\n",
            "Epoch 28/30\n",
            "140/140 - 1s - 4ms/step - accuracy: 0.9443 - loss: 0.2510\n",
            "Epoch 29/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9438 - loss: 0.2501\n",
            "Epoch 30/30\n",
            "140/140 - 0s - 2ms/step - accuracy: 0.9500 - loss: 0.2496\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7af0bde77520>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding the validation set\n",
        "\n",
        "model.fit(x=scaled_train_samples,\n",
        "          y=train_lables,\n",
        "          batch_size=15,\n",
        "          epochs=30,\n",
        "          validation_split = 0.1,\n",
        "          shuffle=True,\n",
        "          verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_M5OYH_eJOO",
        "outputId": "9fb712eb-57fe-449a-f266-da5bb609baf3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "126/126 - 2s - 19ms/step - accuracy: 0.5423 - loss: 0.6755 - val_accuracy: 0.5667 - val_loss: 0.6665\n",
            "Epoch 2/30\n",
            "126/126 - 1s - 6ms/step - accuracy: 0.6497 - loss: 0.6469 - val_accuracy: 0.7190 - val_loss: 0.6334\n",
            "Epoch 3/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.7608 - loss: 0.6040 - val_accuracy: 0.7571 - val_loss: 0.5811\n",
            "Epoch 4/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.8328 - loss: 0.5440 - val_accuracy: 0.8381 - val_loss: 0.5143\n",
            "Epoch 5/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.8624 - loss: 0.4828 - val_accuracy: 0.8667 - val_loss: 0.4503\n",
            "Epoch 6/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.8889 - loss: 0.4239 - val_accuracy: 0.8667 - val_loss: 0.3963\n",
            "Epoch 7/30\n",
            "126/126 - 0s - 3ms/step - accuracy: 0.8947 - loss: 0.3775 - val_accuracy: 0.9143 - val_loss: 0.3489\n",
            "Epoch 8/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9042 - loss: 0.3412 - val_accuracy: 0.9143 - val_loss: 0.3143\n",
            "Epoch 9/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9111 - loss: 0.3156 - val_accuracy: 0.9286 - val_loss: 0.2920\n",
            "Epoch 10/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9206 - loss: 0.2994 - val_accuracy: 0.9143 - val_loss: 0.2775\n",
            "Epoch 11/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9169 - loss: 0.2883 - val_accuracy: 0.9143 - val_loss: 0.2672\n",
            "Epoch 12/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9201 - loss: 0.2810 - val_accuracy: 0.9333 - val_loss: 0.2552\n",
            "Epoch 13/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9249 - loss: 0.2745 - val_accuracy: 0.9286 - val_loss: 0.2516\n",
            "Epoch 14/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9238 - loss: 0.2704 - val_accuracy: 0.9333 - val_loss: 0.2455\n",
            "Epoch 15/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9222 - loss: 0.2668 - val_accuracy: 0.9286 - val_loss: 0.2423\n",
            "Epoch 16/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9317 - loss: 0.2644 - val_accuracy: 0.9286 - val_loss: 0.2405\n",
            "Epoch 17/30\n",
            "126/126 - 0s - 3ms/step - accuracy: 0.9217 - loss: 0.2620 - val_accuracy: 0.9333 - val_loss: 0.2345\n",
            "Epoch 18/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9280 - loss: 0.2597 - val_accuracy: 0.9286 - val_loss: 0.2352\n",
            "Epoch 19/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9259 - loss: 0.2580 - val_accuracy: 0.9333 - val_loss: 0.2305\n",
            "Epoch 20/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9270 - loss: 0.2570 - val_accuracy: 0.9286 - val_loss: 0.2322\n",
            "Epoch 21/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9323 - loss: 0.2551 - val_accuracy: 0.9286 - val_loss: 0.2315\n",
            "Epoch 22/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9302 - loss: 0.2542 - val_accuracy: 0.9333 - val_loss: 0.2263\n",
            "Epoch 23/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9328 - loss: 0.2533 - val_accuracy: 0.9286 - val_loss: 0.2288\n",
            "Epoch 24/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9291 - loss: 0.2524 - val_accuracy: 0.9333 - val_loss: 0.2251\n",
            "Epoch 25/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9286 - loss: 0.2517 - val_accuracy: 0.9333 - val_loss: 0.2259\n",
            "Epoch 26/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9333 - loss: 0.2508 - val_accuracy: 0.9333 - val_loss: 0.2246\n",
            "Epoch 27/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9317 - loss: 0.2503 - val_accuracy: 0.9333 - val_loss: 0.2229\n",
            "Epoch 28/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9286 - loss: 0.2492 - val_accuracy: 0.9333 - val_loss: 0.2207\n",
            "Epoch 29/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9328 - loss: 0.2487 - val_accuracy: 0.9333 - val_loss: 0.2209\n",
            "Epoch 30/30\n",
            "126/126 - 0s - 2ms/step - accuracy: 0.9307 - loss: 0.2478 - val_accuracy: 0.9333 - val_loss: 0.2191\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7952e1c9ee00>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the test data**"
      ],
      "metadata": {
        "id": "ir_0w0SZioWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = []\n",
        "test_samples = []\n",
        "\n",
        "for i in range(10):\n",
        "  # 5% of younger individual who did experience side effects\n",
        "  random_younger = randint(13,64)\n",
        "  test_samples.append(random_younger)\n",
        "  test_labels.append(1)\n",
        "\n",
        "  # 5% older individuals who did not experience side effects\n",
        "  random_older = randint(65,100)\n",
        "  test_samples.append(random_older)\n",
        "  test_labels.append(0)\n",
        "\n",
        "for i in range(200):\n",
        "  # 95% of younger individuals who did not experience side effects\n",
        "  random_younger = randint(13,64)\n",
        "  test_samples.append(random_younger)\n",
        "  test_labels.append(0)\n",
        "\n",
        "  # 95% of older individuals who did experience side effects\n",
        "  random_older = randint(65,100)\n",
        "  test_samples.append(random_older)\n",
        "  test_labels.append(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ky0hQurqjSuH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = np.array(test_samples)\n",
        "test_labels = np.array(test_labels)\n",
        "scaled_test_samples = scalar.fit_transform(test_samples.reshape(-1,1))"
      ],
      "metadata": {
        "id": "8y5njYQPity7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**"
      ],
      "metadata": {
        "id": "RT4HoopGjnhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)\n",
        "for i in predictions:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCCs-aV3jqJg",
        "outputId": "13eb5fc4-e52b-478f-d26f-f7f86f7f9ba1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91943526 0.08056474]\n",
            "[0.04065194 0.95934796]\n",
            "[0.98017734 0.01982266]\n",
            "[0.04805184 0.9519481 ]\n",
            "[0.89312464 0.10687523]\n",
            "[0.05996817 0.94003177]\n",
            "[0.9803966  0.01960331]\n",
            "[0.35080752 0.64919245]\n",
            "[0.9800873  0.01991277]\n",
            "[0.05079129 0.9492087 ]\n",
            "[0.96249133 0.03750864]\n",
            "[0.03435048 0.9656494 ]\n",
            "[0.98071826 0.01928175]\n",
            "[0.03246746 0.9675326 ]\n",
            "[0.9800872  0.01991277]\n",
            "[0.35080752 0.64919245]\n",
            "[0.59159297 0.408407  ]\n",
            "[0.02445552 0.97554433]\n",
            "[0.9811701  0.01882992]\n",
            "[0.03843724 0.96156275]\n",
            "[0.9811701  0.01882992]\n",
            "[0.04298855 0.95701134]\n",
            "[0.946606   0.05339404]\n",
            "[0.04545312 0.9545469 ]\n",
            "[0.8752521  0.12474772]\n",
            "[0.03435048 0.9656494 ]\n",
            "[0.8752521  0.12474772]\n",
            "[0.03843724 0.96156275]\n",
            "[0.9412299  0.05877012]\n",
            "[0.03633863 0.96366143]\n",
            "[0.98061246 0.01938759]\n",
            "[0.04298855 0.95701134]\n",
            "[0.98071826 0.01928175]\n",
            "[0.07271814 0.9272818 ]\n",
            "[0.91943526 0.08056474]\n",
            "[0.06379654 0.93620354]\n",
            "[0.6382471  0.36175293]\n",
            "[0.03246746 0.9675326 ]\n",
            "[0.9351584  0.06484169]\n",
            "[0.19713019 0.80286974]\n",
            "[0.96249133 0.03750864]\n",
            "[0.09018797 0.909812  ]\n",
            "[0.9805818  0.01941817]\n",
            "[0.03068439 0.96931565]\n",
            "[0.91943526 0.08056474]\n",
            "[0.09018797 0.909812  ]\n",
            "[0.9800668  0.01993322]\n",
            "[0.04805184 0.9519481 ]\n",
            "[0.8752522  0.12474773]\n",
            "[0.07788545 0.92211455]\n",
            "[0.98103243 0.0189676 ]\n",
            "[0.04805184 0.9519481 ]\n",
            "[0.98095876 0.01904121]\n",
            "[0.02739846 0.97260165]\n",
            "[0.9795086  0.02049139]\n",
            "[0.39692795 0.60307205]\n",
            "[0.955636   0.04436396]\n",
            "[0.16776682 0.83223325]\n",
            "[0.98061246 0.01938759]\n",
            "[0.08371282 0.9162872 ]\n",
            "[0.6824324  0.31756753]\n",
            "[0.07788544 0.92211443]\n",
            "[0.9781699  0.02183012]\n",
            "[0.08371282 0.9162871 ]\n",
            "[0.98061246 0.01938759]\n",
            "[0.05996817 0.94003177]\n",
            "[0.98103243 0.0189676 ]\n",
            "[0.04298855 0.95701134]\n",
            "[0.975072   0.02492795]\n",
            "[0.04065195 0.959348  ]\n",
            "[0.9803966  0.01960331]\n",
            "[0.04065194 0.95934796]\n",
            "[0.90738815 0.09261184]\n",
            "[0.05996817 0.94003177]\n",
            "[0.96775657 0.03224345]\n",
            "[0.03068439 0.96931565]\n",
            "[0.95926666 0.04073327]\n",
            "[0.12383712 0.87616295]\n",
            "[0.9556361  0.04436397]\n",
            "[0.1055678  0.89443225]\n",
            "[0.98071826 0.01928175]\n",
            "[0.10556779 0.8944322 ]\n",
            "[0.9811701  0.01882992]\n",
            "[0.16776682 0.83223325]\n",
            "[0.9280559  0.07194412]\n",
            "[0.07271814 0.9272818 ]\n",
            "[0.91943526 0.08056474]\n",
            "[0.03843724 0.96156275]\n",
            "[0.6382471  0.36175293]\n",
            "[0.39692795 0.60307205]\n",
            "[0.98092824 0.01907175]\n",
            "[0.11433139 0.8856686 ]\n",
            "[0.89312464 0.10687523]\n",
            "[0.3073154 0.6926846]\n",
            "[0.98071826 0.01928175]\n",
            "[0.04298855 0.95701134]\n",
            "[0.98092824 0.01907175]\n",
            "[0.07271814 0.9272818 ]\n",
            "[0.9800873  0.01991277]\n",
            "[0.04298855 0.9570114 ]\n",
            "[0.85208124 0.14791869]\n",
            "[0.04545312 0.9545469 ]\n",
            "[0.9811701  0.01882992]\n",
            "[0.09018797 0.909812  ]\n",
            "[0.97382295 0.02617714]\n",
            "[0.05367806 0.94632185]\n",
            "[0.97193545 0.0280645 ]\n",
            "[0.03068439 0.96931565]\n",
            "[0.6382471  0.36175293]\n",
            "[0.03435048 0.96564955]\n",
            "[0.44495568 0.5550443 ]\n",
            "[0.02445552 0.97554433]\n",
            "[0.98061246 0.01938759]\n",
            "[0.03633862 0.9636613 ]\n",
            "[0.9781699  0.02183012]\n",
            "[0.03633862 0.9636613 ]\n",
            "[0.97730166 0.02269832]\n",
            "[0.1971302 0.8028698]\n",
            "[0.9073882  0.09261183]\n",
            "[0.03435048 0.96564955]\n",
            "[0.98103243 0.0189676 ]\n",
            "[0.02899629 0.97100365]\n",
            "[0.6824324  0.31756753]\n",
            "[0.26699743 0.7330025 ]\n",
            "[0.955636   0.04436396]\n",
            "[0.04065194 0.95934796]\n",
            "[0.4940344 0.5059656]\n",
            "[0.07788544 0.92211443]\n",
            "[0.9719355 0.0280645]\n",
            "[0.03843724 0.96156275]\n",
            "[0.98103243 0.0189676 ]\n",
            "[0.02899629 0.97100365]\n",
            "[0.54322803 0.45677197]\n",
            "[0.03435048 0.9656494 ]\n",
            "[0.9652701  0.03472985]\n",
            "[0.39692795 0.60307205]\n",
            "[0.7612221  0.23877788]\n",
            "[0.02310195 0.9768981 ]\n",
            "[0.96775657 0.03224345]\n",
            "[0.09018797 0.90981203]\n",
            "[0.91943526 0.08056474]\n",
            "[0.11433139 0.8856686 ]\n",
            "[0.4940344 0.5059656]\n",
            "[0.05079129 0.9492087 ]\n",
            "[0.90738815 0.09261184]\n",
            "[0.05671914 0.9432808 ]\n",
            "[0.54322803 0.45677197]\n",
            "[0.08371282 0.9162871 ]\n",
            "[0.9805055  0.01949455]\n",
            "[0.02899629 0.9710037 ]\n",
            "[0.98106474 0.01893528]\n",
            "[0.06379654 0.93620354]\n",
            "[0.89312464 0.10687523]\n",
            "[0.03246746 0.9675326 ]\n",
            "[0.98092824 0.01907175]\n",
            "[0.06379654 0.93620354]\n",
            "[0.97730166 0.02269832]\n",
            "[0.04545312 0.9545469 ]\n",
            "[0.9556361  0.04436397]\n",
            "[0.04545312 0.9545469 ]\n",
            "[0.9803966  0.01960331]\n",
            "[0.11433139 0.8856686 ]\n",
            "[0.6382471  0.36175293]\n",
            "[0.39692795 0.60307205]\n",
            "[0.59159297 0.408407  ]\n",
            "[0.05079129 0.9492087 ]\n",
            "[0.946606   0.05339404]\n",
            "[0.39692795 0.60307205]\n",
            "[0.85208124 0.14791869]\n",
            "[0.02739846 0.9726016 ]\n",
            "[0.9803966  0.01960331]\n",
            "[0.12383712 0.87616295]\n",
            "[0.7952066 0.2047933]\n",
            "[0.05367806 0.94632185]\n",
            "[0.98092824 0.01907175]\n",
            "[0.05367806 0.94632185]\n",
            "[0.9803966  0.01960331]\n",
            "[0.39692795 0.60307205]\n",
            "[0.98071826 0.01928175]\n",
            "[0.12383711 0.8761629 ]\n",
            "[0.8752521  0.12474772]\n",
            "[0.03633862 0.9636613 ]\n",
            "[0.98061246 0.01938759]\n",
            "[0.09018797 0.909812  ]\n",
            "[0.97193545 0.0280645 ]\n",
            "[0.05079129 0.9492087 ]\n",
            "[0.9805818  0.01941817]\n",
            "[0.04298855 0.95701134]\n",
            "[0.9556361  0.04436397]\n",
            "[0.26699746 0.73300254]\n",
            "[0.95926666 0.04073327]\n",
            "[0.23021114 0.76978886]\n",
            "[0.98017734 0.01982266]\n",
            "[0.06800929 0.93199074]\n",
            "[0.9802874  0.01971269]\n",
            "[0.3073154 0.6926846]\n",
            "[0.9805818  0.01941817]\n",
            "[0.08371282 0.9162871 ]\n",
            "[0.9194352  0.08056473]\n",
            "[0.03246746 0.9675326 ]\n",
            "[0.54322803 0.45677197]\n",
            "[0.10556779 0.8944322 ]\n",
            "[0.946606   0.05339404]\n",
            "[0.35080752 0.64919245]\n",
            "[0.97730166 0.02269832]\n",
            "[0.04065194 0.95934796]\n",
            "[0.9699162  0.03008374]\n",
            "[0.26699743 0.7330025 ]\n",
            "[0.98103243 0.0189676 ]\n",
            "[0.03068439 0.96931565]\n",
            "[0.9803966  0.01960331]\n",
            "[0.09749689 0.9025032 ]\n",
            "[0.90738815 0.09261184]\n",
            "[0.03843724 0.96156275]\n",
            "[0.98095876 0.01904121]\n",
            "[0.10556779 0.8944322 ]\n",
            "[0.72355855 0.2764414 ]\n",
            "[0.02739846 0.97260165]\n",
            "[0.9699163  0.03008374]\n",
            "[0.09749687 0.90250313]\n",
            "[0.975072   0.02492796]\n",
            "[0.09749689 0.9025032 ]\n",
            "[0.9803966  0.01960331]\n",
            "[0.26699743 0.7330025 ]\n",
            "[0.9800668  0.01993322]\n",
            "[0.10556779 0.8944322 ]\n",
            "[0.96775657 0.03224345]\n",
            "[0.04298855 0.95701134]\n",
            "[0.9280559  0.07194412]\n",
            "[0.04805184 0.95194817]\n",
            "[0.98050547 0.01949455]\n",
            "[0.08371282 0.9162871 ]\n",
            "[0.7952066 0.2047933]\n",
            "[0.02310195 0.9768981 ]\n",
            "[0.8254634  0.17453666]\n",
            "[0.02899629 0.97100365]\n",
            "[0.97193545 0.0280645 ]\n",
            "[0.02899629 0.97100365]\n",
            "[0.9592667  0.04073327]\n",
            "[0.02899629 0.9710037 ]\n",
            "[0.98071826 0.01928175]\n",
            "[0.09749689 0.9025032 ]\n",
            "[0.9800872  0.01991277]\n",
            "[0.04545312 0.9545469 ]\n",
            "[0.9514532  0.04854682]\n",
            "[0.07788544 0.92211443]\n",
            "[0.9808522  0.01914773]\n",
            "[0.07788544 0.92211443]\n",
            "[0.9699163  0.03008374]\n",
            "[0.03435048 0.96564955]\n",
            "[0.8254634  0.17453666]\n",
            "[0.04805184 0.9519481 ]\n",
            "[0.7612221  0.23877788]\n",
            "[0.11433139 0.8856686 ]\n",
            "[0.9699162  0.03008374]\n",
            "[0.02588631 0.97411364]\n",
            "[0.9800668  0.01993322]\n",
            "[0.12383712 0.87616295]\n",
            "[0.9699163  0.03008374]\n",
            "[0.02588631 0.97411364]\n",
            "[0.98061246 0.01938759]\n",
            "[0.06800929 0.93199074]\n",
            "[0.9811701  0.01882992]\n",
            "[0.23021114 0.76978886]\n",
            "[0.6382471  0.36175293]\n",
            "[0.3073154 0.6926846]\n",
            "[0.98050547 0.01949455]\n",
            "[0.04545312 0.9545469 ]\n",
            "[0.9800668  0.01993322]\n",
            "[0.11433139 0.8856686 ]\n",
            "[0.85208124 0.14791869]\n",
            "[0.09018797 0.909812  ]\n",
            "[0.85208124 0.14791869]\n",
            "[0.04298855 0.95701134]\n",
            "[0.98061246 0.01938759]\n",
            "[0.39692795 0.60307205]\n",
            "[0.9802874  0.01971269]\n",
            "[0.07271814 0.9272818 ]\n",
            "[0.9781699  0.02183012]\n",
            "[0.06800929 0.93199074]\n",
            "[0.946606   0.05339404]\n",
            "[0.03843724 0.96156275]\n",
            "[0.96249133 0.03750864]\n",
            "[0.04805184 0.9519481 ]\n",
            "[0.7612221  0.23877788]\n",
            "[0.03068439 0.96931565]\n",
            "[0.9351583  0.06484168]\n",
            "[0.03068439 0.96931565]\n",
            "[0.9811701  0.01882992]\n",
            "[0.05367807 0.9463219 ]\n",
            "[0.9514532  0.04854682]\n",
            "[0.04805184 0.9519481 ]\n",
            "[0.98071826 0.01928175]\n",
            "[0.05079129 0.9492087 ]\n",
            "[0.59159297 0.408407  ]\n",
            "[0.10556779 0.8944322 ]\n",
            "[0.9803966  0.01960331]\n",
            "[0.02588631 0.97411364]\n",
            "[0.9808235  0.01917647]\n",
            "[0.05079129 0.9492087 ]\n",
            "[0.6382471  0.36175293]\n",
            "[0.03068439 0.96931565]\n",
            "[0.85208124 0.14791869]\n",
            "[0.05367806 0.94632185]\n",
            "[0.98103243 0.0189676 ]\n",
            "[0.07788544 0.92211443]\n",
            "[0.9802874  0.01971269]\n",
            "[0.05996817 0.94003177]\n",
            "[0.9194352  0.08056473]\n",
            "[0.04298855 0.9570114 ]\n",
            "[0.9652701  0.03472985]\n",
            "[0.02899629 0.97100365]\n",
            "[0.72355855 0.2764414 ]\n",
            "[0.02899629 0.97100365]\n",
            "[0.6382471  0.36175293]\n",
            "[0.02588631 0.97411364]\n",
            "[0.96249133 0.03750864]\n",
            "[0.06379654 0.93620354]\n",
            "[0.82546335 0.17453665]\n",
            "[0.05367807 0.9463219 ]\n",
            "[0.9802874  0.01971269]\n",
            "[0.03633862 0.9636613 ]\n",
            "[0.8254634  0.17453666]\n",
            "[0.39692795 0.60307205]\n",
            "[0.96249133 0.03750864]\n",
            "[0.04298855 0.95701134]\n",
            "[0.9805818  0.01941817]\n",
            "[0.26699743 0.7330025 ]\n",
            "[0.6824325  0.31756756]\n",
            "[0.05996817 0.9400318 ]\n",
            "[0.7952066 0.2047933]\n",
            "[0.04065194 0.95934796]\n",
            "[0.9652701  0.03472985]\n",
            "[0.02310195 0.9768981 ]\n",
            "[0.9800872  0.01991277]\n",
            "[0.05671914 0.9432808 ]\n",
            "[0.9800872  0.01991277]\n",
            "[0.14200373 0.8579962 ]\n",
            "[0.97950864 0.02049139]\n",
            "[0.05367807 0.9463219 ]\n",
            "[0.9805818  0.01941817]\n",
            "[0.26699743 0.7330025 ]\n",
            "[0.91943526 0.08056474]\n",
            "[0.11433139 0.8856686 ]\n",
            "[0.98082346 0.01917647]\n",
            "[0.16776682 0.83223325]\n",
            "[0.8752521  0.12474772]\n",
            "[0.03068439 0.96931565]\n",
            "[0.9412299  0.05877012]\n",
            "[0.07271814 0.92728186]\n",
            "[0.9781699  0.02183012]\n",
            "[0.23021114 0.76978886]\n",
            "[0.85208124 0.14791869]\n",
            "[0.11433139 0.8856686 ]\n",
            "[0.9652701  0.03472985]\n",
            "[0.04298855 0.95701134]\n",
            "[0.97193545 0.0280645 ]\n",
            "[0.03633862 0.9636613 ]\n",
            "[0.975072   0.02492795]\n",
            "[0.07271814 0.92728186]\n",
            "[0.96249133 0.03750864]\n",
            "[0.03843724 0.96156275]\n",
            "[0.98092824 0.01907175]\n",
            "[0.16776682 0.83223325]\n",
            "[0.9280559  0.07194412]\n",
            "[0.04065194 0.95934796]\n",
            "[0.96775657 0.03224345]\n",
            "[0.09018797 0.909812  ]\n",
            "[0.9699163  0.03008374]\n",
            "[0.03435048 0.96564955]\n",
            "[0.6824324  0.31756753]\n",
            "[0.03435048 0.9656494 ]\n",
            "[0.98071826 0.01928175]\n",
            "[0.08371282 0.9162871 ]\n",
            "[0.4940344 0.5059656]\n",
            "[0.1971302 0.8028698]\n",
            "[0.98082346 0.01917647]\n",
            "[0.3073154 0.6926846]\n",
            "[0.9802874  0.01971269]\n",
            "[0.12383711 0.8761629 ]\n",
            "[0.91943526 0.08056474]\n",
            "[0.07788544 0.92211443]\n",
            "[0.72355855 0.2764414 ]\n",
            "[0.07271814 0.9272818 ]\n",
            "[0.98095876 0.01904121]\n",
            "[0.06379654 0.93620354]\n",
            "[0.9808522  0.01914773]\n",
            "[0.06379654 0.93620354]\n",
            "[0.9699163  0.03008374]\n",
            "[0.23021114 0.76978886]\n",
            "[0.97621226 0.02378766]\n",
            "[0.06800929 0.93199074]\n",
            "[0.9811701  0.01882992]\n",
            "[0.02899629 0.97100365]\n",
            "[0.8254634  0.17453666]\n",
            "[0.06800929 0.93199074]\n",
            "[0.4940344 0.5059656]\n",
            "[0.05367806 0.94632185]\n",
            "[0.54322803 0.45677197]\n",
            "[0.03843724 0.96156275]\n",
            "[0.8254634  0.17453666]\n",
            "[0.04298855 0.95701134]\n",
            "[0.98071826 0.01928175]\n",
            "[0.03633862 0.9636613 ]\n",
            "[0.9514532  0.04854682]\n",
            "[0.06800929 0.93199074]\n",
            "[0.98095876 0.01904121]\n",
            "[0.23021114 0.76978886]\n",
            "[0.9466059  0.05339404]\n",
            "[0.14200374 0.8579963 ]\n",
            "[0.9699162  0.03008374]\n",
            "[0.11433139 0.8856686 ]\n",
            "[0.98073906 0.01926099]\n",
            "[0.06800929 0.93199074]\n",
            "[0.9280559  0.07194412]\n",
            "[0.04545312 0.9545469 ]\n",
            "[0.96775657 0.03224345]\n",
            "[0.3073154 0.6926846]\n",
            "[0.9194352  0.08056473]\n",
            "[0.3073154 0.6926846]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting rounding-off values for each input\n",
        "rounded_predictions = np.argmax(predictions, axis=-1)\n",
        "for i in rounded_predictions:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92_EW34zkdrb",
        "outputId": "b29c53fe-909e-49b5-cf75-6cf0d0dcfaab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(y_true=test_labels, y_pred=rounded_predictions)\n",
        "recall = recall_score(y_true=test_labels, y_pred=rounded_predictions)\n",
        "f1 = f1_score(y_true=test_labels, y_pred=rounded_predictions)\n",
        "\n",
        "print(f'Precision: {precision:.3f}')\n",
        "print(f'Recall: {recall:.3f}')\n",
        "print(f'F1 Score: {f1:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1uWxDg2lbjB",
        "outputId": "093aaa2a-052e-4209-a22c-26c9d13d3fbd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.930\n",
            "Recall: 0.952\n",
            "F1 Score: 0.941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#display confusion metrix\n",
        "\n",
        "cm = ConfusionMatrixDisplay.from_predictions(test_labels, rounded_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "-MybivGpluTK",
        "outputId": "4466e30e-7a95-456f-b579-8e5b42402f13"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}